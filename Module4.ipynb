{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're using Google Colab, please run these commands first\n",
    "# !wget https://github.com/dvgodoy/PyTorch101_AI_Plus/raw/main/quiz.zip -O quiz.zip\n",
    "# !unzip -qo quiz.zip\n",
    "# !wget https://raw.githubusercontent.com/dvgodoy/PyTorch101_AI_Plus/main/simple_linear_regression.py -O simple_linear_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"<style>.container { width:90% !important; }.text_cell_render, .output_text {font-family: Lato;font-size: 18px;line-height: 1.5;}.CodeMirror {font-size: 16px;}</style>\"\"\"))\n",
    "from quiz.jupyterquiz import display_quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i simple_linear_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
    "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
    "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Fh8LOI0yYT7"
   },
   "source": [
    "## Model: making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A03THT7YybBn"
   },
   "source": [
    "In PyTorch, a **model** is represented by a regular **Python class** that inherits from the [**Module**](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class.\n",
    "\n",
    "The most fundamental methods it needs to implement are:\n",
    "\n",
    "* **`__init__(self)`**: **it defines the parts that make up the model** —in our case, two parameters, **b** and **w**.\n",
    "\n",
    "* **`forward(self, x)`**: it performs the **actual computation**, that is, it **outputs a prediction**, given the input **x**.\n",
    "\n",
    "Let’s build a proper (yet simple) model for our regression task. It should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNMj2ScHyoXU"
   },
   "outputs": [],
   "source": [
    "class ManualLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "        w = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "\n",
    "        # To make \"b\" and \"w\" real parameters of the model, we need to wrap them with nn.Parameter\n",
    "        self.b = nn.Parameter(b)\n",
    "        self.w = nn.Parameter(w)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Computes the outputs / predictions\n",
    "        return self.b + self.w * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a4CN2oGK0G7z"
   },
   "source": [
    "### Parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FBc6HURx0F2i"
   },
   "source": [
    "In the **\\__init__** method, we define our **two parameters**, **b** and **w**, using the [**Parameter()**](https://bit.ly/309iFQ6) class, to tell PyTorch these **tensors should be considered parameters of the model they are an attribute of**.\n",
    "\n",
    "Why should we care about that? By doing so, we can use our model’s [**parameters()**](https://bit.ly/3jT0Hte[) method to retrieve **an iterator over all model’s parameters**, even those parameters of **nested models**, that we can use to feed our optimizer (instead of building a list of parameters ourselves!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Nwf_kZPhz0Qw",
    "outputId": "902fcc06-2fb3-452c-c929-f1303080a894"
   },
   "outputs": [],
   "source": [
    "dummy = ManualLinearRegression()\n",
    "\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-5BiAQs08Tn"
   },
   "source": [
    "Moreover, we can get the **current values for all parameters** using our model’s [**state_dict()**](https://bit.ly/3f8mnOs) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "htdYIsSD0q2G",
    "outputId": "5ce48458-e93d-414f-d75f-cd7d4989da5e"
   },
   "outputs": [],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIWl41iKdJdP"
   },
   "source": [
    "### state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WU5er3Y4MdO0"
   },
   "source": [
    "The **state_dict()** of a given model is simply a Python dictionary that **maps each layer / parameter to its corresponding tensor**. But only **learnable** parameters are included, as its purpose is to keep track of parameters that are going to be updated by the **optimizer**.\n",
    "\n",
    "The **optimizer** itself also has a **state_dict()**, which contains its internal state, as well as the hyperparameters used.\n",
    "\n",
    "---\n",
    "\n",
    "It turns out **state_dicts** can also be used for **checkpointing** a model, as we will see later down the line.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "fPlsgkPUemlh",
    "outputId": "b0f29d45-bb84-4fd4-9c69-9a7e17669450"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(dummy.parameters(), lr=1e-1)\n",
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJk570c41MlG"
   },
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlTBJ4H21WSj"
   },
   "source": [
    "**IMPORTANT**: we need to **send our model to the same device where the data is**. If our data is made of GPU tensors, our model must “live” inside the GPU as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nYJYMvYE1N-Q",
    "outputId": "a318eea6-eaa7-4625-c094-a3324d4fdfe9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model and send it at once to the device\n",
    "model = ManualLinearRegression().to(device)\n",
    "\n",
    "# We can also inspect its parameters using its state_dict\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxg4yCviqhJT"
   },
   "source": [
    "### Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NAAng-mqmdP"
   },
   "source": [
    "The **forward pass** is the moment when the model **makes predictions**.\n",
    "\n",
    "---\n",
    "\n",
    "You should **NOT call the `forward(x)`** method, though. You should **call the whole model itself**, as in **`model(x)`** to perform a forward pass and output predictions.\n",
    "\n",
    "---\n",
    "\n",
    "Otherwise, your model's _hooks_ will not work (if you have them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuXlvnf-qlw_"
   },
   "outputs": [],
   "source": [
    "yhat = model(x_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QG2VxJhf1v_a"
   },
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbHFyO-22Amu"
   },
   "source": [
    "<h2><b><i>\"What does train() do? It only sets the mode!\"</b></i></h2>\n",
    "\n",
    "In PyTorch, models have a [**train()**](https://bit.ly/30VW2Ox) method which, somewhat disappointingly, **does NOT perform a training step**. Its only purpose is to **set the model to training mode**. \n",
    "\n",
    "Why is this important? Some models may use mechanisms like [**Dropout**](https://bit.ly/2X7v5pU), for instance, which have **distinct behaviors in training and evaluation phases**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Sl-Sd_1f1k--",
    "outputId": "311151e2-4017-4043-ae98-e8bb0c79f2a3"
   },
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "n_epochs = 1000\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "# Now the optimizers uses the parameters from the model\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Sets model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Step 1\n",
    "    # No more manual prediction!\n",
    "    # yhat = b + w * x_tensor\n",
    "    yhat = model(x_train_tensor)\n",
    "    \n",
    "    # Step 2\n",
    "    loss = loss_fn(yhat, y_train_tensor)\n",
    "    # Step 3\n",
    "    loss.backward()\n",
    "    # Step 4\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cD_yXamT2V7r"
   },
   "source": [
    "Now, the printed statements will look like this — final values for parameters **b** and **w** are still the same, so everything is ok :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGrzI0tw2pUX"
   },
   "source": [
    "### Nested Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hpp-gTuB23xK"
   },
   "source": [
    "In our model, we manually created two parameters to perform a linear regression. \n",
    "\n",
    "---\n",
    "\n",
    "You are **not** limited to defining parameters, though… **models can contain other models as its attributes** as well, so you can easily nest them. We’ll see an example of this shortly as well.\n",
    "\n",
    "---\n",
    "\n",
    "Let’s use PyTorch’s [**Linear**](https://bit.ly/2Ezu181) model as an attribute of our own, thus creating a nested model.\n",
    "\n",
    "Even though this clearly is a contrived example, as we are pretty much wrapping the underlying model without adding anything useful (or, at all!) to it, it illustrates well the concept.\n",
    "\n",
    "In the **`__init__`** method, we created an attribute that contains our **nested `Linear` model**.\n",
    "\n",
    "In the **`forward()`** method, we **call the nested model itself** to perform the forward pass (notice, we are **not** calling `self.linear.forward(x)`!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amK4WCg72rVB"
   },
   "outputs": [],
   "source": [
    "class LayerLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Now it only takes a call to the layer to make predictions\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTaDWLJq3djj"
   },
   "source": [
    "Now, if we call the **parameters()** method of this model, **PyTorch will figure the parameters of its attributes in a recursive way**.\n",
    "\n",
    "You can also add new `Linear` attributes and, even if you don’t use them at all in the forward pass, they will **still** be listed under `parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "396v3N5A3ONO",
    "outputId": "b72889c5-4eef-422e-f56a-7ef2b44d477e"
   },
   "outputs": [],
   "source": [
    "dummy = LayerLinearRegression()\n",
    "\n",
    "list(dummy.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "lRDodDDg3XEs",
    "outputId": "cca27cc1-6e98-4037-9208-affec81e220a"
   },
   "outputs": [],
   "source": [
    "dummy.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1KcS2nS2LxpI"
   },
   "source": [
    "### Layers\n",
    "\n",
    "A **Linear** model can be seen as a **layer** in a neural network.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/dvgodoy/PyTorch101_AI_Plus/main/images/layer.png\" width=\"50%\" height=\"50%\">\n",
    "</p>\n",
    "\n",
    "In the example above, the **hidden layer** would be `nn.Linear(3, 5)` and the **output layer** would be `nn.Linear(5, 1)`.\n",
    "\n",
    "\n",
    "There are **MANY** different layers that can be uses in PyTorch:\n",
    "- [Convolution Layers](https://pytorch.org/docs/stable/nn.html#convolution-layers)\n",
    "- [Pooling Layers](https://pytorch.org/docs/stable/nn.html#pooling-layers)\n",
    "- [Padding Layers](https://pytorch.org/docs/stable/nn.html#padding-layers)\n",
    "- [Non-linear Activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)\n",
    "- [Normalization Layers](https://pytorch.org/docs/stable/nn.html#normalization-layers)\n",
    "- [Recurrent Layers](https://pytorch.org/docs/stable/nn.html#recurrent-layers)\n",
    "- [Transformer Layers](https://pytorch.org/docs/stable/nn.html#transformer-layers)\n",
    "- [Linear Layers](https://pytorch.org/docs/stable/nn.html#linear-layers)\n",
    "- [Dropout Layers](https://pytorch.org/docs/stable/nn.html#dropout-layers)\n",
    "- [Sparse Layers (embbedings)](https://pytorch.org/docs/stable/nn.html#sparse-layers)\n",
    "- [Vision Layers](https://pytorch.org/docs/stable/nn.html#vision-layers)\n",
    "- [DataParallel Layers (multi-GPU)](https://pytorch.org/docs/stable/nn.html#dataparallel-layers-multi-gpu-distributed)\n",
    "- [Flatten Layer](https://pytorch.org/docs/stable/nn.html#flatten)\n",
    "\n",
    "We have just used a **Linear** layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7G3-9GX2sRe"
   },
   "source": [
    "### Sequential Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8G3evlAo37Gj"
   },
   "source": [
    "<h2><b><i>Run-of-the-mill layers? Sequential model!</b></i></h2>\n",
    "\n",
    "Our model was simple enough… You may be thinking: “*why even bother to build a class for it?!*” Well, you have a point…\n",
    "\n",
    "For **straightforward models**, that use **run-of-the-mill layers**, where the output of a layer is sequentially fed as an input to the next, we can use a, er… [**Sequential**](https://bit.ly/3hRQTxP) model :-)\n",
    "\n",
    "In our case, we would build a Sequential model with a single argument, that is, the Linear layer we used to train our linear regression. The model would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt9ssm5w2vQa"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZt_4Z3U4KpE"
   },
   "source": [
    "Simple enough, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgJ1Oi1R4RAF"
   },
   "source": [
    "### Training Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZ_wUvVA4TEP"
   },
   "source": [
    "So far, we’ve defined:\n",
    "* an **optimizer**\n",
    "\n",
    "* a **loss function**\n",
    "\n",
    "* a **model**\n",
    "\n",
    "Would the training loop **change** if we were using a **different optimizer**, or **loss**, or even **model**? If not, how can we make it more generic?\n",
    "\n",
    "Well, I guess we could say all these lines of code **perform a training step**, given those **three elements** (optimizer, loss and model),the **features** and the **labels**.\n",
    "\n",
    "So, how about **writing a function that takes those three elements** and **returns another function that performs a training step**, taking a set of features and labels as arguments and returning the corresponding loss?\n",
    "\n",
    "*For an overview of higher-order functions, check my recently published post: [Functions That Return Functions: Higher-Order Functions and Decorators in Python with Examples](https://towardsdatascience.com/functions-that-return-functions-higher-order-functions-and-decorators-in-python-with-examples-4282742cdd3e)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step_fn(model, loss_fn, optimizer):\n",
    "    # Builds function that performs a step in the train loop\n",
    "    def perform_train_step_fn(x, y):\n",
    "        # Sets model to TRAIN mode\n",
    "        model.train()\n",
    "        \n",
    "        # Step 1 - Computes our model's predicted output - forward pass\n",
    "        yhat = model(x)\n",
    "        # Step 2 - Computes the loss\n",
    "        loss = loss_fn(yhat, y)\n",
    "        # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
    "        loss.backward()\n",
    "        # Step 4 - Updates parameters using gradients and the learning rate\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    # Returns the function that will be called inside the train loop\n",
    "    return perform_train_step_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1z-JIko4ysl"
   },
   "source": [
    "Then we can use this general-purpose function to build a **train_step_fn()** function to be called inside our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "train_step_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_fn(x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4F60DNI64zBk",
    "outputId": "8d5eb83c-e276-4fc1-d840-b68f7cd5dfe9"
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "## Model Configuration ##\n",
    "#########################\n",
    "lr = 1e-1\n",
    "torch.manual_seed(13)\n",
    "\n",
    "# Create a MODEL, a LOSS FUNCTION and an OPTIMIZER\n",
    "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkqKUEaj5EOi"
   },
   "source": [
    "Now our code should look like this… see how **tiny** the training loop is now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2ysa76u44nX",
    "outputId": "e5d8df37-4578-4373-fd7b-771d531182b5"
   },
   "outputs": [],
   "source": [
    "####################\n",
    "## Model Training ##\n",
    "####################\n",
    "\n",
    "# Creates the train_step function for our model, loss function and optimizer\n",
    "train_step_fn = make_train_step_fn(model, loss_fn, optimizer)\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "# For each epoch...\n",
    "for epoch in range(n_epochs):\n",
    "    # Performs one train step and returns the corresponding loss\n",
    "    loss = train_step_fn(x_train_tensor, y_train_tensor)\n",
    "    losses.append(loss)\n",
    "    \n",
    "# Checks model's parameters\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "colab_type": "code",
    "id": "jOnHnxJQDU5C",
    "outputId": "20b12834-b138-4fe5-fdcf-7c609a29745f"
   },
   "outputs": [],
   "source": [
    "plt.plot(losses[:200])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_quiz('#./quiz/quiz4.b64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
